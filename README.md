# 1C Code Bench

Система бенчмаркинга для тестирования и оценки производительности кода 1С:Предприятие.

## Обзор

1C Code Bench — это комплексный инструмент для бенчмаркинга, предназначенный для тестирования и измерения производительности фрагментов кода 1С:Предприятие. Система автоматизирует процесс загрузки кода в базу данных 1С, его выполнения и сбора метрик производительности.

## Возможности

- **Автоматизированное тестирование кода**: Автоматическая загрузка и выполнение фрагментов кода 1С
- **Бенчмаркинг производительности**: Измерение времени выполнения и метрик производительности
- **Пакетная обработка**: Выполнение нескольких тестовых образцов последовательно
- **Анализ результатов**: Парсинг и анализ логов выполнения
- **Интеграция с базой данных**: Бесшовная интеграция с базами данных 1С:Предприятие

## Структура проекта

```
bench/
├── bench/                  # Основные модули бенчмаркинга
│   ├── benchmark_runner.py # Основная логика выполнения бенчмарков
│   ├── one_c_runner.py     # Интеграция с 1С:Предприятие
│   └── constants.py        # Константы конфигурации
├── data/                   # Тестовые данные и шаблоны
├── SampleProcessor.xml     # Конфигурация внешней обработки 1С
├── SampleProcessor.epf     # Внешняя обработка 1С
└── playground.py           # Скрипт для тестирования и разработки
```

## Требования

- Python 3.8+
- Платформа 1С:Предприятие (рекомендуется 8.3.24+)
- Необходимые пакеты Python:
  - pandas
  - tqdm

## Установка

1. Клонируйте репозиторий
2. Установите необходимые пакеты:
   ```bash
   pip install pandas tqdm
   ```
3. Настройте пути к 1С:Предприятие в `constants.py`

## Конфигурация

Обновите следующие константы в `bench/constants.py`:

- `DESIGNER_PATH`: Путь к исполняемому файлу конфигуратора 1С:Предприятие
- `DATABASE_PATH`: Путь к вашей базе данных 1С
- `PROCESSING_PATH`: Путь к внешней обработке

## Использование

### Базовое использование

```python
from bench.benchmark_runner import BenchmarkRunner

# Инициализация запускателя бенчмарков
runner = BenchmarkRunner()

# Запуск бенчмарка на тестовом файле
results = runner.run("test_samples.csv")
```

### Формат данных образцов

Тестовые образцы должны предоставляться в формате CSV со следующими колонками:
- `gt_solution`: Код 1С для выполнения (для пробного запуска)
- `output`: Код 1С для выполнения (для обычного запуска)
- `validation`: Код для валидации результатов
- `run_context`: Код настройки и контекст

### Запуск бенчмарков

```python
# Запуск с пользовательскими параметрами
runner = BenchmarkRunner()
results = runner.run(
    filename="my_tests.csv",
    dry_run=False  # Установите True для режима валидации
)
```

## Разработка

### Запуск тестов

Используйте скрипт `playground.py` для разработки и тестирования:

```bash
python playground.py
```

### Добавление новых тестовых случаев

1. Создайте тестовые образцы в формате CSV
2. Включите необходимые фрагменты кода 1С
3. Добавьте логику валидации
4. Запустите через систему бенчмаркинга

## Архитектура

Система состоит из нескольких ключевых компонентов:

- **BenchmarkRunner**: Организует весь процесс бенчмаркинга
- **OneCEngine**: Обрабатывает операции с базой данных 1С:Предприятие
- **Sample Processor**: Внешняя обработка 1С для выполнения кода

## Соображения производительности

- Каждый тест выполняется с настраиваемым таймаутом (по умолчанию: 2 минуты)
- Операции с базой данных оптимизированы для пакетной обработки
- Логи парсятся для извлечения метрик производительности

## Устранение неполадок

### Распространенные проблемы

1. **Ошибки разрешений**: Убедитесь, что 1С:Предприятие имеет соответствующие разрешения
2. **Проблемы с кодировкой**: Файлы должны быть сохранены в кодировке UTF-8
3. **Конфигурация путей**: Проверьте правильность всех путей в constants.py

### Режим отладки

Включите вывод отладочной информации, раскомментировав операторы print в модулях запускателя.

## Анализ логов

Система парсит логи выполнения 1С для определения:
- **Статус компиляции**: Успешно ли скомпилировался код
- **Статус выполнения**: Выполнился ли код без ошибок
- **Валидация результата**: Соответствует ли вывод ожидаемым результатам

## Участие в разработке

1. Сделайте форк репозитория
2. Создайте ветку функциональности
3. Добавьте тесты для новой функциональности
4. Отправьте pull request
